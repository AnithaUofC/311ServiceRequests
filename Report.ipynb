{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6989a1cc-6d52-4f1c-bd8d-2399704b3eb3",
   "metadata": {},
   "source": [
    "\n",
    "#    311 Service Requests Data Analysis and Visualization\n",
    "##   DATA 601 Project Report - Team 4 \n",
    "###  Team Members : Anitha Joseph, Jincy Thomas, Megha Radhakrishnan Sanitha "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baccd508-b8fd-43f6-beeb-992d92168195",
   "metadata": {},
   "source": [
    "\n",
    "#### INTRODUCTION\n",
    "\n",
    "    311 is a non-emergency government service that helps citizens to report issues and access city information. It can be accessed by phone, online, or through mobile apps and often includes multilingual support and services for vulnerable populations like the senior residents. The 311 system collects all requests, which are then routed to the responsible city department for resolution. It operates 24/7 and allows users to track the progress of their requests, ensuring transparency and accountability. Thus the 311 services make the lives of the residents easier and saves their time by eliminating the need to contact multiple departments for resolving their concerns. The user-friendly interface of 311 also makes the communication with the local government effortless, convenient and accessible for everyone.\n",
    "\n",
    "    Analysis of 311 data over a long period of time helps us in determining the most frequent service requests which can be addressed more efficiently by allocating adequate resources. This can also be used to identify the efficiencies of different departments and the gaps where improvement is required. Seasonal patterns and long term trends can also be identified which can be used to predict the future demands and optimize the public services. By tracking types of requests, response times, and areas with frequent complaints, resources can be allocated more effectively, and operational inefficiencies can be identified and resolved. The residents will get a clear picture regarding the handling of their concerns which promotes transparency. Proactive planning is made possible, allowing for better resource distribution and improved service delivery. Ultimately, systemic issues can be identified, and solutions can be developed,leading to improved city planning and enhanced community satisfaction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069c3b64-88a6-4455-a6be-415471292354",
   "metadata": {},
   "source": [
    "\n",
    "#### GUIDING QUESTIONS\n",
    "\n",
    "    The major guiding questions for the analysis of 311 service requests and the the ways in which the insights from answering these questions can be utilized are as follows:\n",
    "    1. Geographic Analysis\n",
    "    ● Which community or location has the largest number of service requests?\n",
    "    ● Are there any specific needs for certain areas?\n",
    "    High need areas can be prioritized and resources can be allocated where they are most required.\n",
    "    \n",
    "    2. Seasonal Trends\n",
    "    ● During which seasons do service requests occur most often?\n",
    "    ● How do service requests change over seasons? Are there any identifiable patterns?\n",
    "    Seasonal patterns are identified thus helping to focus resources effectively.\n",
    "    \n",
    "    3. Request Sources\n",
    "    ● What is the primary source of service requests: phone calls or online submissions (web)?\n",
    "    Interfaces can be upgraded based on user preferences.\n",
    "    \n",
    "    4. Types of Service Requests\n",
    "    ● What is the service requested most frequently?\n",
    "    Helps to identify and allocate adequate resources for the most needed service.\n",
    "    \n",
    "    5. Response Efficiency\n",
    "    ● Which agency handles the most and least number of service requests?\n",
    "    ● What is the average response rate and time for resolving for service requests?\n",
    "    ● Who are the most efficient agents in terms of response and resolution times?\n",
    "    ● How does the response efficiency vary across different years?\n",
    "    Track the department efficiencies and identify areas where improvement is required.\n",
    "    \n",
    "    6. Trends Over Time\n",
    "    ● How has the volume and type of service requests changed over the past five years?\n",
    "    ● Are there noticeable trends in requests that could be used for future planning?\n",
    "    Future demands can be anticipated, allowing for better preparedness."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d10602ec-e413-4602-a51b-e2d227d37bbe",
   "metadata": {},
   "source": [
    "\n",
    "#### DATASET\n",
    "\n",
    "##### Data description\n",
    "\n",
    "    The data for this analysis is sourced from The City of Calgary’s open data portal, specifically the \"311 Service Requests -Services and Amenities\" dataset (The City of Calgary,2025) . We have included public service requests submitted via 311 for 2 years- 2023 and 2024, consisting of 1062842 rows and 15 columns, structured in a tabular format. Each row represents an individual service request.\n",
    "    \n",
    "##### Format and Structure\n",
    "    The data consists of several datasets depending on the city or organization's open data portal. Each dataset typically contains the following columns: \n",
    "\n",
    "    Column                Datatype   Description\n",
    "    service_request_id     object    The unique identifier for an individual request.\n",
    "    requested_date         object    The date the request was submitted.\n",
    "    updated_date           object    The most recent date the request was updated.\n",
    "    closed_date            object    The date the request was closed.\n",
    "    status_description     object    The current status of the request (e.g. open, closed).\n",
    "    source                 object    The channel used to submit the request\n",
    "    service_name           object    The type of service requested.\n",
    "    agency_responsible     object    The department responsible for this request.\n",
    "    address               float64    The location of the service request (if applicable).\n",
    "    comm_code              object    The community code associated with the service request location.\n",
    "    comm_name              object    The community name associated with the service request location.\n",
    "    location_type          object    The type of location information provided for this service request.\n",
    "    longitude             float64    The longitude of the service request.\n",
    "    latitude              float64    The latitude of the service request.\n",
    "    point                  object    The spatial coordinates based on latitude and longitude."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c694fe1b-f6ea-42a1-9378-b813c979cea5",
   "metadata": {},
   "source": [
    "    The data is sourced from The City of Calgary’s open data portal, 311 Service Requests - Services and Amenities.The data is publicly available and used with permission as per the open data policy. This data is provided by the City of Calgary at https://data.calgary.ca/Services-and-Amenities/311-Service-Requests/iahh-g8bj/about_data and all usagecomplies with their data usage and attribution requirements listed in the license URL https://data.calgary.ca/d/Open-Data-Terms/u45n-7awa ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f70e7fd-e42c-48b3-9f32-221fb8a90891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing and Importing libraries \n",
    "\n",
    "#!pip install geopandas\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import geopandas as gpd\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.patches as mpatches\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0c16f80-d8d3-49bd-9873-4051af0bc739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLASS</th>\n",
       "      <th>CLASS_CODE</th>\n",
       "      <th>COMM_CODE</th>\n",
       "      <th>NAME</th>\n",
       "      <th>SECTOR</th>\n",
       "      <th>SRG</th>\n",
       "      <th>COMM_STRUCTURE</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>POINT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Residential</td>\n",
       "      <td>1</td>\n",
       "      <td>BED</td>\n",
       "      <td>BEDDINGTON HEIGHTS</td>\n",
       "      <td>NORTH</td>\n",
       "      <td>ESTABLISHED</td>\n",
       "      <td>1960s/1970s</td>\n",
       "      <td>-114.09</td>\n",
       "      <td>51.13</td>\n",
       "      <td>POINT (-114.08502139544244 51.13163280873361)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Residential</td>\n",
       "      <td>1</td>\n",
       "      <td>EVN</td>\n",
       "      <td>EVANSTON</td>\n",
       "      <td>NORTH</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>2010s</td>\n",
       "      <td>-114.11</td>\n",
       "      <td>51.17</td>\n",
       "      <td>POINT (-114.1124526074949 51.17109493109596)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Residential</td>\n",
       "      <td>1</td>\n",
       "      <td>KIL</td>\n",
       "      <td>KILLARNEY/GLENGARRY</td>\n",
       "      <td>CENTRE</td>\n",
       "      <td>ESTABLISHED</td>\n",
       "      <td>1950s</td>\n",
       "      <td>-114.13</td>\n",
       "      <td>51.03</td>\n",
       "      <td>POINT (-114.13172726984385 51.031548429038665)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Residential</td>\n",
       "      <td>1</td>\n",
       "      <td>BRA</td>\n",
       "      <td>BRAESIDE</td>\n",
       "      <td>SOUTH</td>\n",
       "      <td>ESTABLISHED</td>\n",
       "      <td>1960s/1970s</td>\n",
       "      <td>-114.11</td>\n",
       "      <td>50.96</td>\n",
       "      <td>POINT (-114.10636591786145 50.955992888964275)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Residential</td>\n",
       "      <td>1</td>\n",
       "      <td>BLM</td>\n",
       "      <td>BELMONT</td>\n",
       "      <td>SOUTH</td>\n",
       "      <td>DEVELOPING</td>\n",
       "      <td>BUILDING OUT</td>\n",
       "      <td>-114.06</td>\n",
       "      <td>50.87</td>\n",
       "      <td>POINT (-114.055251748252 50.86868365691495)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>Residual Sub Area</td>\n",
       "      <td>4</td>\n",
       "      <td>ABT</td>\n",
       "      <td>AMBLETON</td>\n",
       "      <td>NORTHWEST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNDEVELOPED</td>\n",
       "      <td>-114.11</td>\n",
       "      <td>51.19</td>\n",
       "      <td>POINT (-114.22275942835957 51.168724389792594)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>Residual Sub Area</td>\n",
       "      <td>4</td>\n",
       "      <td>12L</td>\n",
       "      <td>12L</td>\n",
       "      <td>SOUTHEAST</td>\n",
       "      <td>FUTURE</td>\n",
       "      <td>UNDEVELOPED</td>\n",
       "      <td>-113.87</td>\n",
       "      <td>50.91</td>\n",
       "      <td>POINT (-113.8715190162749 50.91435050102264)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>Residual Sub Area</td>\n",
       "      <td>4</td>\n",
       "      <td>12I</td>\n",
       "      <td>12I</td>\n",
       "      <td>SOUTH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNDEVELOPED</td>\n",
       "      <td>-114.16</td>\n",
       "      <td>50.99</td>\n",
       "      <td>POINT (-114.16441971345019 50.986651529493514)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>Residual Sub Area</td>\n",
       "      <td>4</td>\n",
       "      <td>01I</td>\n",
       "      <td>01I</td>\n",
       "      <td>SOUTH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNDEVELOPED</td>\n",
       "      <td>-114.16</td>\n",
       "      <td>50.99</td>\n",
       "      <td>POINT (-114.16441971345019 50.986651529493514)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>Residual Sub Area</td>\n",
       "      <td>4</td>\n",
       "      <td>11A</td>\n",
       "      <td>11A</td>\n",
       "      <td>SOUTH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNDEVELOPED</td>\n",
       "      <td>-114.16</td>\n",
       "      <td>50.99</td>\n",
       "      <td>POINT (-114.16441971345019 50.986651529493514)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>318 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 CLASS  CLASS_CODE COMM_CODE                 NAME     SECTOR  \\\n",
       "0          Residential           1       BED   BEDDINGTON HEIGHTS      NORTH   \n",
       "1          Residential           1       EVN             EVANSTON      NORTH   \n",
       "2          Residential           1       KIL  KILLARNEY/GLENGARRY     CENTRE   \n",
       "3          Residential           1       BRA             BRAESIDE      SOUTH   \n",
       "4          Residential           1       BLM              BELMONT      SOUTH   \n",
       "..                 ...         ...       ...                  ...        ...   \n",
       "313  Residual Sub Area           4       ABT             AMBLETON  NORTHWEST   \n",
       "314  Residual Sub Area           4       12L                  12L  SOUTHEAST   \n",
       "315  Residual Sub Area           4       12I                  12I      SOUTH   \n",
       "316  Residual Sub Area           4       01I                  01I      SOUTH   \n",
       "317  Residual Sub Area           4       11A                  11A      SOUTH   \n",
       "\n",
       "             SRG COMM_STRUCTURE  longitude  latitude  \\\n",
       "0    ESTABLISHED    1960s/1970s    -114.09     51.13   \n",
       "1       COMPLETE          2010s    -114.11     51.17   \n",
       "2    ESTABLISHED          1950s    -114.13     51.03   \n",
       "3    ESTABLISHED    1960s/1970s    -114.11     50.96   \n",
       "4     DEVELOPING   BUILDING OUT    -114.06     50.87   \n",
       "..           ...            ...        ...       ...   \n",
       "313          NaN    UNDEVELOPED    -114.11     51.19   \n",
       "314       FUTURE    UNDEVELOPED    -113.87     50.91   \n",
       "315          NaN    UNDEVELOPED    -114.16     50.99   \n",
       "316          NaN    UNDEVELOPED    -114.16     50.99   \n",
       "317          NaN    UNDEVELOPED    -114.16     50.99   \n",
       "\n",
       "                                              POINT  \n",
       "0     POINT (-114.08502139544244 51.13163280873361)  \n",
       "1      POINT (-114.1124526074949 51.17109493109596)  \n",
       "2    POINT (-114.13172726984385 51.031548429038665)  \n",
       "3    POINT (-114.10636591786145 50.955992888964275)  \n",
       "4       POINT (-114.055251748252 50.86868365691495)  \n",
       "..                                              ...  \n",
       "313  POINT (-114.22275942835957 51.168724389792594)  \n",
       "314    POINT (-113.8715190162749 50.91435050102264)  \n",
       "315  POINT (-114.16441971345019 50.986651529493514)  \n",
       "316  POINT (-114.16441971345019 50.986651529493514)  \n",
       "317  POINT (-114.16441971345019 50.986651529493514)  \n",
       "\n",
       "[318 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading datasets\n",
    "\n",
    "# 311_Service_Requests\n",
    "df = pd.read_csv('/Users/jincythomas/Downloads/311_Service_Requests_2yrs.csv')\n",
    "\n",
    "# Community Sectors\n",
    "community_data=pd.read_csv(\"CSV_SECTORS.csv\")\n",
    "\n",
    "# Geographic data for geo-visualization\n",
    "multi_polygon_df = pd.read_csv(\"Community_District_Boundaries_GeoJson.csv\")\n",
    "#display(df)\n",
    "display(community_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53e60d0-fef5-4d32-a058-d680569430fa",
   "metadata": {},
   "source": [
    "## Data cleaning nad preprocessing\n",
    "\n",
    "Handling Missing and Unwanted Data\n",
    "\n",
    "• Handling Missing Data: Drop columns with more than 10% missing values.\n",
    "\n",
    "• Handling Unwanted Data: Drop requestes created before Jan-1-2023 and after Dec-31-2024.\n",
    "\n",
    "• Handling Missing Community Code: Fill Community Code with Community name.\n",
    "\n",
    "• Handling Missing Longitude: Fill Longitude with Median value.\n",
    "\n",
    "• Handling Missing Latitude: Fill Latitude with median value.\n",
    "\n",
    "• Handling Missing Point with it's mode value\n",
    "\n",
    "• Replace values in 'source' column with corresponding service source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dfd11ef-3a2d-4c0e-b32f-2fa1484eb7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "\u001b[1mData Analysis and Visualization of Building Emergency Benchmarking\u001b[0m\n",
      "----------------------------------------------------------------------------\n",
      "1.\tShape of the Dataset: (1093918, 15)\n",
      "2.\tNumber of records or rows of the DataFrame: 1093918\n",
      "3.\tColumns and Data types of each column:\n",
      " service_request_id     object\n",
      "requested_date         object\n",
      "updated_date           object\n",
      "closed_date            object\n",
      "status_description     object\n",
      "source                 object\n",
      "service_name           object\n",
      "agency_responsible     object\n",
      "address               float64\n",
      "comm_code              object\n",
      "comm_name              object\n",
      "location_type          object\n",
      "longitude             float64\n",
      "latitude              float64\n",
      "point                  object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------------------------------------------------------------------\")\n",
    "print(\"\\033[1m\"+\"Data Analysis and Visualization of Building Emergency Benchmarking\"+\"\\033[0m\")\n",
    "print(\"----------------------------------------------------------------------------\")\n",
    "\n",
    "#display shape, columns, and data types\n",
    "print(\"1.\\tShape of the Dataset:\", df.shape)\n",
    "print(\"2.\\tNumber of records or rows of the DataFrame:\", df.shape[0])\n",
    "print(\"3.\\tColumns and Data types of each column:\\n\", df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82e07ef4-6ee9-4282-9f0c-d75ee94e3304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mMissing Count per column:\u001b[0m\n",
      "╒════════════════════╤═════════════════╤══════════════════════╕\n",
      "│                    │   Missing Count │   Missing Percentage │\n",
      "╞════════════════════╪═════════════════╪══════════════════════╡\n",
      "│ service_request_id │     0           │                 0    │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ requested_date     │     0           │                 0    │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ updated_date       │     0           │                 0    │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ closed_date        │ 39714           │                 3.63 │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ status_description │     0           │                 0    │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ source             │     0           │                 0    │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ service_name       │     0           │                 0    │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ agency_responsible │   205           │                 0.02 │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ address            │     1.09392e+06 │               100    │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ comm_code          │ 76289           │                 6.97 │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ comm_name          │ 76288           │                 6.97 │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ location_type      │ 76076           │                 6.95 │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ longitude          │ 76300           │                 6.97 │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ latitude           │ 76300           │                 6.97 │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ point              │ 76300           │                 6.97 │\n",
      "╘════════════════════╧═════════════════╧══════════════════════╛\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>service_request_id</th>\n",
       "      <th>requested_date</th>\n",
       "      <th>updated_date</th>\n",
       "      <th>closed_date</th>\n",
       "      <th>status_description</th>\n",
       "      <th>source</th>\n",
       "      <th>service_name</th>\n",
       "      <th>agency_responsible</th>\n",
       "      <th>address</th>\n",
       "      <th>comm_code</th>\n",
       "      <th>comm_name</th>\n",
       "      <th>location_type</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>point</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23-00000797</td>\n",
       "      <td>2023/01/02 12:00:00 AM</td>\n",
       "      <td>2023/01/10 12:00:00 AM</td>\n",
       "      <td>2023/01/10 12:00:00 AM</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Other</td>\n",
       "      <td>Finance - ONLINE TIPP Agreement Request</td>\n",
       "      <td>CFOD - Finance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23-00001045</td>\n",
       "      <td>2023/01/02 12:00:00 AM</td>\n",
       "      <td>2024/01/11 12:00:00 AM</td>\n",
       "      <td>2024/01/11 12:00:00 AM</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Other</td>\n",
       "      <td>Active Living Program Application</td>\n",
       "      <td>CS - Recreation and Social Programs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23-00001163</td>\n",
       "      <td>2023/01/02 12:00:00 AM</td>\n",
       "      <td>2023/01/06 12:00:00 AM</td>\n",
       "      <td>2023/01/06 12:00:00 AM</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Phone</td>\n",
       "      <td>CN - Registered Social Worker Letter</td>\n",
       "      <td>CS - Calgary Neighbourhoods</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23-00001191</td>\n",
       "      <td>2023/01/02 12:00:00 AM</td>\n",
       "      <td>2024/05/19 12:00:00 AM</td>\n",
       "      <td>2023/01/10 12:00:00 AM</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Other</td>\n",
       "      <td>CT - Lost Property</td>\n",
       "      <td>OS - Calgary Transit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23-00001584</td>\n",
       "      <td>2023/01/02 12:00:00 AM</td>\n",
       "      <td>2023/01/04 12:00:00 AM</td>\n",
       "      <td>2023/01/04 12:00:00 AM</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Other</td>\n",
       "      <td>Recreation - Arena Booking Application</td>\n",
       "      <td>CS - Calgary Recreation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  service_request_id          requested_date            updated_date  \\\n",
       "0        23-00000797  2023/01/02 12:00:00 AM  2023/01/10 12:00:00 AM   \n",
       "1        23-00001045  2023/01/02 12:00:00 AM  2024/01/11 12:00:00 AM   \n",
       "2        23-00001163  2023/01/02 12:00:00 AM  2023/01/06 12:00:00 AM   \n",
       "3        23-00001191  2023/01/02 12:00:00 AM  2024/05/19 12:00:00 AM   \n",
       "4        23-00001584  2023/01/02 12:00:00 AM  2023/01/04 12:00:00 AM   \n",
       "\n",
       "              closed_date status_description source  \\\n",
       "0  2023/01/10 12:00:00 AM             Closed  Other   \n",
       "1  2024/01/11 12:00:00 AM             Closed  Other   \n",
       "2  2023/01/06 12:00:00 AM             Closed  Phone   \n",
       "3  2023/01/10 12:00:00 AM             Closed  Other   \n",
       "4  2023/01/04 12:00:00 AM             Closed  Other   \n",
       "\n",
       "                              service_name  \\\n",
       "0  Finance - ONLINE TIPP Agreement Request   \n",
       "1        Active Living Program Application   \n",
       "2     CN - Registered Social Worker Letter   \n",
       "3                       CT - Lost Property   \n",
       "4   Recreation - Arena Booking Application   \n",
       "\n",
       "                    agency_responsible  address comm_code comm_name  \\\n",
       "0                       CFOD - Finance      NaN       NaN       NaN   \n",
       "1  CS - Recreation and Social Programs      NaN       NaN       NaN   \n",
       "2          CS - Calgary Neighbourhoods      NaN       NaN       NaN   \n",
       "3                 OS - Calgary Transit      NaN       NaN       NaN   \n",
       "4              CS - Calgary Recreation      NaN       NaN       NaN   \n",
       "\n",
       "  location_type  longitude  latitude point  \n",
       "0           NaN        NaN       NaN   NaN  \n",
       "1           NaN        NaN       NaN   NaN  \n",
       "2           NaN        NaN       NaN   NaN  \n",
       "3           NaN        NaN       NaN   NaN  \n",
       "4           NaN        NaN       NaN   NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inspecting  data\n",
    "\n",
    "missingDataSum = df.isna().sum()\n",
    "missingDataPercentage = (df.isnull().mean() * 100).round(2)\n",
    "missingData = pd.DataFrame({\n",
    "    \"Missing Count\": missingDataSum,\n",
    "    \"Missing Percentage\": missingDataPercentage\n",
    "})\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "print(\"\\n\\033[1m\"+\"Missing Count per column:\"+\"\\033[0m\")\n",
    "print(tabulate(missingData, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "#The dataframe(DF) is copied to another DF variable if in case there is a need for original DF\n",
    "originalDF = df\n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c30ff1c-abcd-4f44-b055-bf53b88183e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns with missing percentage more than 40% missing values are: ['address']\n",
      "\n",
      "Count of deleted request which are recieved on or after 2025-01-01 and before 2023-01-01: 31076\n",
      "\n",
      "Community name with community code null and community name exists: []\n",
      "\n",
      "Community Code is filled with Community name for [] community\n",
      "\n",
      "Longitude and latitude missing values are replaced with its corresponding median\n",
      "\n",
      "Point missing values are replaced with its mode\n"
     ]
    }
   ],
   "source": [
    "# Handling Missing Data\n",
    "columnNameDropped = missingDataPercentage[missingDataPercentage >= 40].index.tolist()\n",
    "print(\"\\nColumns with missing percentage more than 40% missing values are:\", columnNameDropped)\n",
    "df = df.drop(columns = missingDataPercentage[missingDataPercentage > 40].index)\n",
    "\n",
    "# Handling Unwanted Data\n",
    "beforeCount = df.shape[0]\n",
    "df = df[(df['requested_date'] < '2025-01-01') & (df['requested_date'] > '2023-01-01')]\n",
    "afterCount =df.shape[0]\n",
    "deletedCount = beforeCount - afterCount\n",
    "print(f\"\\nCount of deleted request which are recieved on or after 2025-01-01 and before 2023-01-01: {deletedCount}\")\n",
    "\n",
    "#Handling Missing Community Code\n",
    "communityNames = df[df['comm_code'].isnull() & df['comm_name'].notnull()]['comm_name'].to_list()\n",
    "print(f\"\\nCommunity name with community code null and community name exists: {communityNames}\")\n",
    "\n",
    "df['comm_code'].fillna(df['comm_name'])\n",
    "print(f\"\\nCommunity Code is filled with Community name for {communityNames} community\")\n",
    "\n",
    "#Handling Missing Longitude and Latitude with their median \n",
    "df['longitude'] = df['longitude'].fillna(df['longitude'].median())\n",
    "df['latitude'] = df['latitude'].fillna(df['latitude'].median())\n",
    "print(\"\\nLongitude and latitude missing values are replaced with its corresponding median\")\n",
    "\n",
    "#Handling Missing Point with the mode\n",
    "df['point'] = df['point'].fillna(df['point'].mode()[0])\n",
    "print(\"\\nPoint missing values are replaced with its mode\")\n",
    "\n",
    "# Replace values in 'source' column with corresponding service source\n",
    "df['source'] = df['source'].replace('Web', 'Web (Online Form)')\n",
    "df['source'] = df['source'].replace('App', 'Mobile App')\n",
    "df['source'] = df['source'].replace('Other','Email & Social Media')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4749826e-f06f-41f8-818e-a7a8cf7f9950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mDate and Time Handling: Modified data type:\u001b[0m\n",
      "Data type of 'requested_date': datetime64[ns]\n",
      "Data type of 'updated_date': datetime64[ns]\n",
      "Data type of 'closed_date': datetime64[ns]\n",
      "\n",
      "\u001b[1mDate and Time Handling: newly created columns are:\u001b[0m\n",
      "For requested_date: request_year, request_month, request_day\n",
      "For updated_date: update_year, update_month, update_day\n",
      "For closed_date: closed_year, closed_month, closed_day\n"
     ]
    }
   ],
   "source": [
    "# Date and Time Handling:\n",
    "#------------------------------------------------------------------------------------------\n",
    "\n",
    "#Convert the Date column to a datetime object\n",
    "df['requested_date'] = pd.to_datetime(df['requested_date'], format = '%Y/%m/%d %I:%M:%S %p')\n",
    "df['updated_date'] = pd.to_datetime(df['updated_date'], format = '%Y/%m/%d %I:%M:%S %p')\n",
    "df['closed_date'] = pd.to_datetime(df['closed_date'], format = '%Y/%m/%d %I:%M:%S %p')\n",
    "\n",
    "print(\"\\n\\033[1m\"+\"Date and Time Handling: Modified data type:\"+\"\\033[0m\")\n",
    "print(f\"Data type of 'requested_date': {df['requested_date'].dtype}\")\n",
    "print(f\"Data type of 'updated_date': {df['updated_date'].dtype}\")\n",
    "print(f\"Data type of 'closed_date': {df['closed_date'].dtype}\")\n",
    "\n",
    "# Converting null values to NaT\n",
    "df['closed_date'] = df['closed_date'].fillna(pd.NaT)\n",
    "\n",
    "#Create new columns for the year, month, and day of the week for requested, updated and closed date columns\n",
    "df['request_year'] = df['requested_date'].dt.year\n",
    "df['request_month'] = df['requested_date'].dt.month\n",
    "df['request_day'] = df['requested_date'].dt.day\n",
    "df['update_year'] = df['updated_date'].dt.year\n",
    "df['update_month'] = df['updated_date'].dt.month\n",
    "df['update_day'] = df['updated_date'].dt.day\n",
    "df['closed_year'] = df['closed_date'].dt.year\n",
    "df['closed_month'] = df['closed_date'].dt.month\n",
    "df['closed_day'] = df['closed_date'].dt.day\n",
    "\n",
    "# Map the numerical days to their names for better readability\n",
    "day_name_map = {0: 'Monday', 1: 'Tuesday', 2: 'Wednesday', 3: 'Thursday', 4: 'Friday', 5: 'Saturday', 6: 'Sunday'}\n",
    "df['day_name'] = df['request_day'].map(day_name_map)\n",
    "\n",
    "# Replacing null values in derived date related columns with 0 and converting the column values to int type\n",
    "df.loc[df['closed_date'].isna(), ['closed_year', 'closed_month', 'closed_day']] = 0\n",
    "df[['request_year', 'request_month', 'request_day']] = df[['request_year', 'request_month', 'request_day']].astype('Int32')\n",
    "df[['update_year', 'update_month', 'update_day']] = df[['update_year', 'update_month', 'update_day']].astype('Int32')\n",
    "df[['closed_year', 'closed_month', 'closed_day']] = df[['closed_year', 'closed_month', 'closed_day']].astype('Int32')\n",
    "\n",
    "\n",
    "print(\"\\n\\033[1m\"+\"Date and Time Handling: newly created columns are:\"+\"\\033[0m\")\n",
    "print(\"For requested_date: request_year, request_month, request_day\")\n",
    "print(\"For updated_date: update_year, update_month, update_day\")\n",
    "print(\"For closed_date: closed_year, closed_month, closed_day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5bd4020d-d836-47d7-aa8e-a3e8ad4c83f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAdditional Columns created are:\u001b[0m\n",
      "\tis_weekend_request\n",
      "\tresponse_time\n",
      "\tduplicate_request\n"
     ]
    }
   ],
   "source": [
    "# Create additional columns:\n",
    "#-------------------------------------------------------------------------\n",
    "\n",
    "#Add a column indicating whether each request date falls on a weekend\n",
    "df['is_weekend_request'] = df['request_day']>= 5\n",
    "\n",
    "#Add a column for time duration to calculate the time took to close the request\n",
    "df['response_time'] = df['closed_date'] - df['requested_date']\n",
    "df['response_time'] = df['response_time'].dt.days\n",
    "\n",
    "#Add a column to see if the request is duplicate or not(Yes means duplicate and No means not a duplicate request)\n",
    "df['duplicate_request'] = df['status_description'].str.contains(r'Duplicate \\(Closed\\)', regex=True)\n",
    "df['duplicate_request'] = df['duplicate_request'].replace({True: 'Yes', False: 'No'})\n",
    "\n",
    "print(\"\\n\\033[1m\"+\"Additional Columns created are:\"+\"\\033[0m\")\n",
    "print(\"\\tis_weekend_request\")\n",
    "print(\"\\tresponse_time\")\n",
    "print(\"\\tduplicate_request\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "077be63b-50cb-4bea-be9b-29b241dea94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAdditional Columns created are:\u001b[0m\n",
      "\tnew_requested_date\n"
     ]
    }
   ],
   "source": [
    "# Season Categorisation of \"Requests\"\n",
    "# Defining Calgary's timezone\n",
    "calgary_tz = pytz.timezone('America/Edmonton')  \n",
    "# Exact UTC times for solstices and equinoxes (taken from Govt of Canada Website)\n",
    "seasons_utc = {\n",
    "    'Spring_2023': '2023-03-20 21:24:00',\n",
    "    'Summer_2023': '2023-06-21 14:57:00',\n",
    "    'Autumn_2023': '2023-09-23 06:50:00',\n",
    "    'Winter_2023': '2023-12-22 03:27:00',\n",
    "    'Spring_2024': '2024-03-20 03:06:00',\n",
    "    'Summer_2024': '2024-06-20 20:50:00',\n",
    "    'Autumn_2024': '2024-09-22 12:43:00',\n",
    "    'Winter_2024': '2024-12-21 09:20:00'\n",
    "}\n",
    "\n",
    "# Converting the UTC times to Calgary local time\n",
    "seasons = {}\n",
    "for season, utc_time_str in seasons_utc.items():\n",
    "    # Converting the UTC string into a datetime object   \n",
    "    utc_time = datetime.strptime(utc_time_str, '%Y-%m-%d %H:%M:%S')\n",
    "    utc_time = pytz.utc.localize(utc_time) \n",
    "    # Converting to Calgary local time\n",
    "    local_time = utc_time.astimezone(calgary_tz)\n",
    "    # Saving the result in the dictionary\n",
    "    seasons[season] = local_time\n",
    "#for key, value in seasons.items():\n",
    "#print(f\"{key}: {value.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "#    print(f\"{key}: {value}\")\n",
    "\n",
    "# Keeping the local time but making it aware for requested_date columns\n",
    "if df['requested_date'].dt.tz is None:\n",
    "    df['new_requested_date'] = df['requested_date'].dt.tz_localize('America/Edmonton')\n",
    "#print(df['new_requested_date'].head())\n",
    "\n",
    "# Categorizing into seasons and creating a new 'season' column\n",
    "# Assigning seasons based on request date\n",
    "def get_season(request_date):\n",
    "    for season, season_date in seasons.items():\n",
    "        if request_date < season_date:\n",
    "            return season\n",
    "    return 'Winter_2024'  # Default to the latest season\n",
    "\n",
    "# Creating new season column \n",
    "df['Season'] = df['new_requested_date'].apply(get_season)\n",
    "\n",
    "# Define the date range\n",
    "start_date = '2023-12-22'\n",
    "end_date = '2023-12-31'\n",
    "# Update the Season column for the specified date range\n",
    "df.loc[(df['requested_date'] >= start_date) & (df['requested_date'] <= end_date), 'Season'] = 'Winter_2023'\n",
    "#display(df)\n",
    "\n",
    "print(\"\\n\\033[1m\"+\"Additional Columns created are:\"+\"\\033[0m\")\n",
    "print(\"\\tnew_requested_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97c869f2-03de-4762-8732-8984169a3388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAdditional Columns created are:\u001b[0m\n",
      "\tcommunity_sector\n"
     ]
    }
   ],
   "source": [
    "#Add column for Community Sector using the community sector csv file\n",
    "def merge_community_sector(main_data, community_data):\n",
    "    # Rename the relevant columns in the community_data for clarity and consistency\n",
    "    community_data.rename(columns={'COMM_CODE': 'comm_code', 'SECTOR': 'community_sector'}, inplace=True)\n",
    "\n",
    "    # Merge the datasets based on the 'comm_code'\n",
    "    merged_data = main_data.merge(community_data[['comm_code', 'community_sector']], on='comm_code', how='left')\n",
    "\n",
    "    return merged_data\n",
    "\n",
    "df = merge_community_sector(df, community_data)\n",
    "print(\"\\n\\033[1m\"+\"Additional Columns created are:\"+\"\\033[0m\")\n",
    "print(\"\\tcommunity_sector\")\n",
    "\n",
    "#Handling Missing for Community related columns\n",
    "df.loc[df['comm_code'].isnull(), 'comm_code'] = \"Community Centrepoint\"\n",
    "df.loc[df['comm_name'].isnull(), 'comm_name'] = \"Community Centrepoint\"\n",
    "df.loc[df['community_sector'].isnull(), 'community_sector'] = \"Community Centrepoint\"\n",
    "\n",
    "# Extract year and month from the requested_date column\n",
    "df['year_month'] = df['requested_date'].dt.to_period('M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4aabe9f-f704-439b-98f1-24a97e47af03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAdditional Columns created are:\u001b[0m\n",
      "\tagency_division\n",
      "\tagency_subdivision\n",
      "\tservice_category\n",
      "\tservice_request\n"
     ]
    }
   ],
   "source": [
    "# Add a column for Divisions of Agency assigned for the requests\n",
    "\n",
    "#Unassigned agencies are assigned to corresponding divisions\n",
    "df.loc[df['agency_responsible'].isnull() & df['service_name'].str.contains('WATR -'), 'agency_responsible'] = 'UEP - Utilities & Environmental Protection'\n",
    "df.loc[df['agency_responsible'].isnull() & df['service_name'].str.contains('PSD -'), 'agency_responsible'] = 'PDS - Planning & Development Services'\n",
    "df.loc[df['agency_responsible'].isnull() & df['service_name'].str.contains('CPI -'), 'agency_responsible'] = 'OSC - Operational Services and Compliance'\n",
    "\n",
    "# agency abbreviations are extracted\n",
    "def extract_division(value):\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    parts = value.split('-')\n",
    "    resultStr = parts[0].strip() if '-' in value else value.strip()\n",
    "    return resultStr\n",
    "\n",
    "\n",
    "df['agency_division'] = df['agency_responsible'].apply(extract_division)\n",
    "\n",
    "#Actual agencies or divisions under Calgary Government\n",
    "agency_division = {\n",
    "    'agency_name': ['Affiliated Organizations', 'Chief Financial Officer Department', 'Corporate Wide Service Requests',\n",
    "                    'Calgary Police & Fire Services', 'Community Services', \"Deputy City Manager's Office\",\n",
    "                   'Elected Officials', 'Fleet and Inventory', 'Information Services','Legal or Legislative Services',\n",
    "                   'Office of the City Auditor','Operational Services and Compliance', 'Partnerships',\n",
    "                   'Planning & Development Services','Project Information and Control Systems', 'Recreation and Social Programs',\n",
    "                    'Transportation', 'Utilities & Environmental Protection'],\n",
    "    'abbreviations': [['AO', 'Affiliated Organizations'], ['CFOD'], ['Corporate Wide Service Requests'], \n",
    "                      ['CPFS'],['CS'], ['DCMO'], \n",
    "                      ['Elected Officials'], ['Fleet and Inventory'], ['IS'], ['LL','LLSS'],\n",
    "                      ['Office of the City Auditor'],['OS','OSC'],['Partnerships'],\n",
    "                      ['PD','PDS'],['PICS'],['Recreation and Social Programs'],\n",
    "                      ['TRAN','Tranc'], ['UEP','Uepc']]\n",
    "}\n",
    "\n",
    "\n",
    "# Create a mapping dictionary\n",
    "mapping = {abbreviation: agency_name \n",
    "           for agency_name, abbreviations in zip(agency_division['agency_name'], agency_division['abbreviations']) \n",
    "           for abbreviation in abbreviations}\n",
    "\n",
    "\n",
    "# Replace the agency_division values with actual agency_name or divisions\n",
    "df['agency_division'] = df['agency_division'].map(mapping)\n",
    "#noDivisionDF = df[df['agency_division'].isnull()]\n",
    "#display(noDivisionDF)\n",
    "agencies= df['agency_division'].unique()\n",
    "    \n",
    "# Iterate through each agency division in the list\n",
    "for division in agencies:\n",
    "    subset_df = df[df['agency_division'] == division]\n",
    "    \n",
    "    # Split the 'agency_responsible' column at the first hyphen and create 'agency_subdivision'\n",
    "    df.loc[df['agency_division'] == division, 'agency_subdivision'] = subset_df['agency_responsible'].apply(\n",
    "        lambda x: x.split('-', 1)[1] if '-' in x else division\n",
    "    )\n",
    "\n",
    "    # Split the 'service_name' column at the first hyphen and create 'service_category'\n",
    "    df.loc[df['agency_division'] == division, 'service_category'] = subset_df['service_name'].apply(\n",
    "        lambda x: x.split('-', 1)[0] if '-' in x else x\n",
    "    )\n",
    "\n",
    "    # Split the 'service_name' column at the first hyphen and create 'service_request'\n",
    "    df.loc[df['agency_division'] == division, 'service_request'] = subset_df['service_name'].apply(\n",
    "        lambda x: x.split('-', 1)[1] if '-' in x else x\n",
    "    )\n",
    "    \n",
    "#Update Service Category names\n",
    "df.loc[df['service_category'] == 'CT', 'service_category'] = 'Calgary Transit'\n",
    "df.loc[df['service_category'] == 'DBBS Inspection', 'service_category'] = 'Development, Business and Building Services'\n",
    "df.loc[df['service_category'] == 'WRS', 'service_category'] = 'Waste and Recycling Services'\n",
    "df.loc[df['service_category'] == 'WATS', 'service_category'] = 'Water Services'\n",
    "df.loc[df['service_category'] == 'Corporate', 'service_category'] = 'Corporate Wide Service Requests'\n",
    "\n",
    "\n",
    "print(\"\\n\\033[1m\"+\"Additional Columns created are:\"+\"\\033[0m\")\n",
    "print(\"\\tagency_division\")\n",
    "print(\"\\tagency_subdivision\")\n",
    "print(\"\\tservice_category\")\n",
    "print(\"\\tservice_request\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "145140c9-8c06-4ec6-ae6c-4650bfc16b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAgency division and the count of requests handles by each division:\u001b[0m\n",
      "For answering the response efficiency, we have considered 1022239 requests\n",
      "Average response time: 12.6 days\n"
     ]
    }
   ],
   "source": [
    "#Filter the records from your dataframe df where closed_date is greater than or equal to requested_date, \n",
    "#closed_date is not null, and duplicate_request is 'No'\n",
    "print(\"\\n\\033[1m\"+\"Agency division and the count of requests handles by each division:\"+\"\\033[0m\")\n",
    "efficiencyDF = df[(df['closed_date'] >= df['requested_date']) & \n",
    "                 (df['closed_date'].notna()) & \n",
    "                 (df['duplicate_request'] == 'No')]\n",
    "print(f\"For answering the response efficiency, we have considered {efficiencyDF.shape[0]} requests\")\n",
    "\n",
    "average_response_time = round(efficiencyDF['response_time'].mean(), 2)\n",
    "print(f\"Average response time: {average_response_time} days\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ce9f30-8fe7-43fb-9474-5c50b016a476",
   "metadata": {},
   "source": [
    "## Information of New Processed Data Set for 311 requests\n",
    "\n",
    "• Shape of the new Processed Dataset.\n",
    "\n",
    "• Count of 311 service requests.\n",
    "\n",
    "• Columns and Data types of each column.\n",
    "\n",
    "• 311 Request 'Status' available.\n",
    "\n",
    "• Agencies resposible for handling service requests.\n",
    "\n",
    "• Count of all distinct service requests.\n",
    "\n",
    "• Count of all distinct service requests for all agencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42cdccbc-2b61-4ffa-9d24-172e713844e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.\tShape of the new Processed Dataset: (1063381, 37)\n",
      "2.\tCount of 311 service requests: 1063381\n",
      "3.\tColumns and Data types of each column:\n",
      "\t\tagency_subdivision  object\n",
      "\t\tclosed_day          Int32\n",
      "\t\tduplicate_request   object\n",
      "\t\tservice_request     object\n",
      "\t\tagency_division     object\n",
      "\t\trequest_day         Int32\n",
      "\t\tclosed_month        Int32\n",
      "\t\trequest_year        Int32\n",
      "\t\tclosed_year         Int32\n",
      "\t\tday_name            object\n",
      "\t\tupdate_year         Int32\n",
      "\t\tcommunity_sector    object\n",
      "\t\tupdate_month        Int32\n",
      "\t\tresponse_time       float64\n",
      "\t\trequest_month       Int32\n",
      "\t\tyear_month          period[M]\n",
      "\t\tupdate_day          Int32\n",
      "\t\tSeason              object\n",
      "\t\tis_weekend_request  boolean\n",
      "\t\tservice_category    object\n",
      "\t\tcommunity_sector_x  object\n",
      "\t\tcommunity_sector_y  object\n",
      "\t\tnew_requested_date  datetime64[ns, America/Edmonton]\n",
      "4.\t311 Request Status available: ['Closed' 'Open' 'Duplicate (Closed)' 'Duplicate (Open)']\n",
      "\ti.\tCount of Open requests: 32788\n",
      "\t\ta.\tCount of Open requests with closed date: 2030\n",
      "\t\tb.\tCount of Open requests with no closed date: 30758\n",
      "\tii.\tCount of Closed requests: 1020204\n",
      "\tiii.\tCount of Duplicate (Open) requests: 1340\n",
      "\tiv.\tCount of Duplicate (Closed) requests: 9049\n",
      "\n",
      "\u001b[1mMissing Count per column:\u001b[0m\n",
      "╒════════════════════╤═════════════════╤══════════════════════╕\n",
      "│                    │   Missing Count │   Missing Percentage │\n",
      "╞════════════════════╪═════════════════╪══════════════════════╡\n",
      "│ service_request_id │               0 │                 0    │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ requested_date     │               0 │                 0    │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ updated_date       │               0 │                 0    │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ closed_date        │           32093 │                 3.02 │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ status_description │               0 │                 0    │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ source             │               0 │                 0    │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ service_name       │               0 │                 0    │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ agency_responsible │               0 │                 0    │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ comm_code          │               0 │                 0    │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ comm_name          │               0 │                 0    │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ location_type      │           73626 │                 6.92 │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ longitude          │               0 │                 0    │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ latitude           │               0 │                 0    │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ point              │               0 │                 0    │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ community_sector_x │               0 │                 0    │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ request_year       │               0 │                 0    │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ request_month      │               0 │                 0    │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ request_day        │               0 │                 0    │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ update_year        │               0 │                 0    │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ update_month       │               0 │                 0    │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ update_day         │               0 │                 0    │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ closed_year        │               0 │                 0    │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ closed_month       │               0 │                 0    │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ closed_day         │               0 │                 0    │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ day_name           │          849653 │                79.9  │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ is_weekend_request │               0 │                 0    │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ response_time      │           32093 │                 3.02 │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ duplicate_request  │               0 │                 0    │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ new_requested_date │               0 │                 0    │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ Season             │               0 │                 0    │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ community_sector_y │           73834 │                 6.94 │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ community_sector   │               0 │                 0    │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ year_month         │               0 │                 0    │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ agency_division    │               0 │                 0    │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ agency_subdivision │               0 │                 0    │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ service_category   │               0 │                 0    │\n",
      "├────────────────────┼─────────────────┼──────────────────────┤\n",
      "│ service_request    │               0 │                 0    │\n",
      "╘════════════════════╧═════════════════╧══════════════════════╛\n"
     ]
    }
   ],
   "source": [
    "print(\"1.\\tShape of the new Processed Dataset:\", df.shape)\n",
    "print(\"2.\\tCount of 311 service requests:\", df.shape[0])\n",
    "print(\"3.\\tColumns and Data types of each column:\")\n",
    "\n",
    "# Get the columns that are in df but not in originalDF\n",
    "newColumns = list(set(df.columns) - set(originalDF.columns))\n",
    "dtypes = df[newColumns].dtypes\n",
    "width = max(len(column) for column in df.columns) + 2\n",
    "for column, dtype in dtypes.items():\n",
    "    print(f\"\\t\\t{column.ljust(width)}{dtype}\")\n",
    "print(f\"4.\\t311 Request Status available: {df['status_description'].unique()}\")\n",
    "#display(df['status_description'].unique())\n",
    "\n",
    "status_counts = df['status_description'].value_counts()\n",
    "dupClosedReqCnt = status_counts['Duplicate (Closed)']\n",
    "dupOpenReqCnt = status_counts['Duplicate (Open)']\n",
    "closedReqCnt = status_counts['Closed']\n",
    "openReqCnt = status_counts['Open']\n",
    "print(f\"\\ti.\\tCount of Open requests: {openReqCnt}\")\n",
    "\n",
    "# Filter requests where status_description is \"open\" but has closed date\n",
    "openButClosedDF = df[(df['status_description'] == 'Open') & (df['closed_date'].notnull())]\n",
    "openReqWithClosedDateCnt = openButClosedDF['status_description'].value_counts()\n",
    "print(f\"\\t\\ta.\\tCount of Open requests with closed date: {openReqWithClosedDateCnt['Open']}\")\n",
    "openDF = df[(df['status_description'] == 'Open') & (df['closed_date'].isnull())]\n",
    "openDF = openDF['status_description'].value_counts()\n",
    "print(f\"\\t\\tb.\\tCount of Open requests with no closed date: {openDF['Open']}\")\n",
    "\n",
    "print(f\"\\tii.\\tCount of Closed requests: {closedReqCnt}\")\n",
    "print(f\"\\tiii.\\tCount of Duplicate (Open) requests: {dupOpenReqCnt}\")\n",
    "print(f\"\\tiv.\\tCount of Duplicate (Closed) requests: {dupClosedReqCnt}\")\n",
    "\n",
    "# Inspect data\n",
    "missingDataSum = df.isna().sum()\n",
    "missingDataPercentage = (df.isnull().mean() * 100).round(2)\n",
    "missingData = pd.DataFrame({\n",
    "    \"Missing Count\": missingDataSum,\n",
    "    \"Missing Percentage\": missingDataPercentage\n",
    "})\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "print(\"\\n\\033[1m\"+\"Missing Count per column:\"+\"\\033[0m\")\n",
    "print(tabulate(missingData, headers='keys', tablefmt='fancy_grid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8f7b679-8936-48f8-b28f-6e331572af16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5.\tCount of all distinct service requests: 638\n",
      "\n",
      "6.\tCount of all distinct service requests for all agencies: 1037\n",
      "\n",
      "7.\tAgencies resposible for handling service requests are:\n",
      "\t\t- Chief Financial Officer Department\n",
      "\t\t- Community Services\n",
      "\t\t- Operational Services and Compliance\n",
      "\t\t- Transportation\n",
      "\t\t- Utilities & Environmental Protection\n",
      "\t\t- Planning & Development Services\n",
      "\t\t- Calgary Police & Fire Services\n",
      "\t\t- Corporate Wide Service Requests\n",
      "\t\t- Project Information and Control Systems\n",
      "\t\t- Partnerships\n",
      "\t\t- Deputy City Manager's Office\n",
      "\t\t- Legal or Legislative Services\n",
      "\t\t- Recreation and Social Programs\n",
      "\t\t- Elected Officials\n",
      "\t\t- Information Services\n",
      "\t\t- Affiliated Organizations\n",
      "\t\t- Fleet and Inventory\n",
      "\t\t- Office of the City Auditor\n"
     ]
    }
   ],
   "source": [
    "# Entire Unique service names\n",
    "unique_service_name_df = df['service_name'].unique()\n",
    "print(\"\\n5.\\tCount of all distinct service requests:\",len(unique_service_name_df))\n",
    "\n",
    "agency_vise_distinct_req = df[['agency_division','agency_subdivision', 'agency_responsible','service_name']].drop_duplicates()\n",
    "print(\"\\n6.\\tCount of all distinct service requests for all agencies:\",len(agency_vise_distinct_req))\n",
    "\n",
    "#agencies= df['agency_division'].unique()\n",
    "print(\"\\n7.\\tAgencies resposible for handling service requests are:\")\n",
    "for agency in agencies:\n",
    "    print(f\"\\t\\t- {agency}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea765860-9c6b-4897-a65f-440d7ace6c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
